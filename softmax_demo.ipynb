{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olcaykursun/Algorithms/blob/main/softmax_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wDlWLbfkJtvu"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "# Simple Linear Regression with the Iris Dataset\n",
        "\n",
        "In this first Colab, you'll explore linear regression with a simple database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZz29MwGgE2Y"
      },
      "source": [
        "## Learning objectives:\n",
        "\n",
        "After doing this exercise, you'll know how to do the following:\n",
        "\n",
        "  * Run Colabs.\n",
        "  * Tune the following [hyperparameters](https://developers.google.com/machine-learning/glossary/#hyperparameter):\n",
        "    * [learning rate](https://developers.google.com/machine-learning/glossary/#learning_rate)\n",
        "    * number of [epochs](https://developers.google.com/machine-learning/glossary/#epoch)\n",
        "    * [batch size](https://developers.google.com/machine-learning/glossary/#batch_size)\n",
        "  * Interpret different kinds of [loss curves](https://developers.google.com/machine-learning/glossary/#loss_curve)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchnxAsaKKqO"
      },
      "source": [
        "## Import relevant modules\n",
        "\n",
        "The following cell imports the packages that the program requires:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n9_cTveKmse"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "try_epochs = [10, 20, 40, 80]\n",
        "try_learning_rates = [0.001, 0.01, 0.1, 0.5, 1, 2, 4]\n",
        "try_batch_sizes = [1, 2, 4]\n",
        "n_runs = 5 #run about 10 times for each combination to get a good estimate for the mean of the loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIpsyJITPcbG"
      },
      "source": [
        "## Define functions that build and train a model\n",
        "\n",
        "The following code defines two functions:\n",
        "\n",
        "  * `build_model(my_learning_rate)`, which builds an empty model.\n",
        "  * `train_model(model, feature, label, epochs)`, which trains the model from the examples (feature and label) you pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvO_beKVP1Ke",
        "outputId": "0dc9ab79-f701-4ad8-8378-a3bba05cc7b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined build_model and train_model\n"
          ]
        }
      ],
      "source": [
        "#@title Define the functions that build and train a model\n",
        "def build_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  # A sequential model contains one or more layers.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,\n",
        "                                  input_shape=(1,)))\n",
        "\n",
        "  # Compile the model topography into code that\n",
        "  # TensorFlow can efficiently execute. Configure\n",
        "  # training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_model(model, feature, label, epochs, batch_size):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the feature values and the label values to the\n",
        "  # model. The model will train for the specified number\n",
        "  # of epochs, gradually learning how the feature values\n",
        "  # relate to the label values.\n",
        "\n",
        "  history = model.fit(x=feature,\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs, verbose=0) #validation_split=0.5\n",
        "\n",
        "  # Gather the trained model's weight and bias.\n",
        "  trained_weight = model.get_weights()[0]\n",
        "  trained_bias = model.get_weights()[1]\n",
        "\n",
        "  # The list of epochs is stored separately from the\n",
        "  # rest of history.\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Gather the history (a snapshot) of each epoch.\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  # Specifically gather the model's root mean\n",
        "  # squared error at each epoch.\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse, model\n",
        "\n",
        "print(\"Defined build_model and train_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF0BFRXTOeR3",
        "outputId": "078f922c-e16d-4040-d0d7-544157b66456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined the plot_the_model and plot_the_loss_curve functions.\n"
          ]
        }
      ],
      "source": [
        "#@title Define the plotting functions\n",
        "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
        "  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
        "\n",
        "  trained_weight = trained_weight[0][0]\n",
        "  trained_bias = trained_bias[0]\n",
        "  # Label the axes.\n",
        "  plt.xlabel(\"feature\")\n",
        "  plt.ylabel(\"label\")\n",
        "\n",
        "  # Plot the feature values vs. label values.\n",
        "  plt.scatter(feature, label)\n",
        "\n",
        "  # Create a red line representing the model. The red line starts\n",
        "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
        "  x0 = feature.min()\n",
        "  y0 = trained_bias + (trained_weight * x0)\n",
        "  x1 = feature.max()\n",
        "  y1 = trained_bias + (trained_weight * x1)\n",
        "  plt.plot([x0, x1], [y0, y1], c='r')\n",
        "\n",
        "  # Render the scatter plot and the red line.\n",
        "  plt.show()\n",
        "\n",
        "def plot_the_loss_curve(epochs, rmse):\n",
        "  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, rmse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
        "  plt.show()\n",
        "\n",
        "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnUSYKw4LUuh",
        "outputId": "ce555532-9258-4081-f7e0-3c5a9de57baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) with m=1.7693334817886353 and c=-7.075587749481201 gives us of an rmse of 0.9775567680262368\n",
            "sepal width (cm) with m=-1.2916473150253296 and c=7.834952354431152 gives us of an rmse of 1.6246024380963402\n",
            "petal length (cm) with m=0.997748076915741 and c=-0.0008598674321547151 gives us of an rmse of 0.005351918154869108\n",
            "petal width (cm) with m=2.1618833541870117 and c=1.1968492269515991 gives us of an rmse of 0.4789826678825887\n",
            "Time taken to run: 5322.6628045\n"
          ]
        }
      ],
      "source": [
        "#@title Try each feature with different hyperparameter combinations for optimization\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "iris_data, _, iris_target, _ = train_test_split(iris.data, iris.target, train_size=0.5)\n",
        "\n",
        "import time\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "best_rmse = np.full(4, np.inf)\n",
        "best_epochs = np.zeros(4)\n",
        "best_learning_rates = np.zeros(4)\n",
        "best_batch_sizes = np.zeros(4)\n",
        "best_m = np.zeros(4)\n",
        "best_c = np.zeros(4)\n",
        "\n",
        "my_label = iris_data[:, 2] #target is petal_length\n",
        "for var in range(4):\n",
        "  my_feature = iris_data[:, var] #use sepal_length to predict the target\n",
        "\n",
        "  for num_epochs in try_epochs:\n",
        "    for learning_rate in try_learning_rates:\n",
        "      for batch_size in try_batch_sizes:\n",
        "        rmses = []\n",
        "        for run in range(n_runs):\n",
        "\n",
        "          initialized_model = build_model(learning_rate)\n",
        "          trained_weight, trained_bias, epochs, rmse, trained_model = train_model(initialized_model, my_feature,\n",
        "                                                            my_label, num_epochs,\n",
        "                                                            batch_size)\n",
        "          y_pred = trained_model.predict(iris.data[:, var], verbose = 0).flatten()\n",
        "          rmse = np.sqrt(mean_squared_error(iris.data[:, 2], y_pred))\n",
        "          rmses.append(rmse)\n",
        "        avg_rmse = sum(rmses)/n_runs\n",
        "        if best_rmse[var] > avg_rmse:\n",
        "          best_rmse[var] = avg_rmse\n",
        "          best_learning_rates[var] = learning_rate\n",
        "          best_batch_sizes[var] = batch_size\n",
        "          best_epochs[var] = num_epochs\n",
        "          best_m[var] = trained_weight[0][0]\n",
        "          best_c[var] = trained_bias[0]\n",
        "\n",
        "  print(f'{iris.feature_names[var]} with m={best_m[var]} and c={best_c[var]} gives us of an rmse of {best_rmse[var]}')\n",
        "\n",
        "t2 = time.perf_counter()\n",
        "print('Time taken to run:',t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrXQJVPU4Y3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af6c96c-b8ff-4317-9f37-c440908ec340"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_rmse=array([0.97755677, 1.62460244, 0.00535192, 0.47898267])\n",
            "best_epochs=array([40., 80., 80., 80.])\n",
            "best_learning_rates=array([0.1 , 0.1 , 0.01, 0.01])\n",
            "best_batch_sizes=array([1., 4., 4., 1.])\n"
          ]
        }
      ],
      "source": [
        "#@title Print the best settings\n",
        "print(f'{best_rmse=}')\n",
        "print(f'{best_epochs=}')\n",
        "print(f'{best_learning_rates=}')\n",
        "print(f'{best_batch_sizes=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7MxY0fAIcFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6727e4f-65c0-4eef-8e1a-de4b3fce6c6f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X[2] ~= 1.77 * X[0] - 7.08\n",
            "X[2] ~= -1.29 * X[1] + 7.83\n",
            "X[2] ~= 1.00 * X[2] - 0.00\n",
            "X[2] ~= 2.16 * X[3] + 1.20\n"
          ]
        }
      ],
      "source": [
        "#@title Print the equations for the regression lines\n",
        "for var in range(4):\n",
        "  if best_c[var] > 0:\n",
        "    print(f'X[2] ~= {best_m[var]:.2f} * X[{var}] + {best_c[var]:.2f}')\n",
        "  else:\n",
        "    print(f'X[2] ~= {best_m[var]:.2f} * X[{var}] - {-best_c[var]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QB_lZKvQeo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdc01a2-7736-4991-f22a-f3d96dd83b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) gives us of an rmse of 0.9478995291745204\n",
            "sepal width (cm) gives us of an rmse of 1.6297173933258418\n",
            "petal length (cm) gives us of an rmse of 0.003536954419188184\n",
            "petal width (cm) gives us of an rmse of 0.48129492560939474\n",
            "Time taken to run: 2801.157854186\n"
          ]
        }
      ],
      "source": [
        "#@title Try to do it faster by running the training epochs cumulatively\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "best_rmse = np.full(4, np.inf)\n",
        "best_epochs = np.zeros(4)\n",
        "best_learning_rates = np.zeros(4)\n",
        "best_batch_sizes = np.zeros(4)\n",
        "\n",
        "my_label = iris_data[:, 2] #target is petal_length\n",
        "for var in range(4):\n",
        "  my_feature = iris_data[:, var] #use sepal_length to predict the target\n",
        "\n",
        "  for learning_rate in try_learning_rates:\n",
        "    for batch_size in try_batch_sizes:\n",
        "      rmses = {num_epochs : [] for num_epochs in try_epochs}\n",
        "      for run in range(n_runs):\n",
        "        initialized_model = build_model(learning_rate)\n",
        "        total_epochs_so_far = 0\n",
        "        for num_epochs in try_epochs:\n",
        "          add_epochs = num_epochs - total_epochs_so_far\n",
        "          total_epochs_so_far = total_epochs_so_far + add_epochs\n",
        "          trained_weight, trained_bias, epochs, rmse, trained_model = train_model(initialized_model, my_feature,\n",
        "                                                            my_label, add_epochs,\n",
        "                                                            batch_size)\n",
        "          y_pred = trained_model.predict(iris.data[:, var], verbose = 0).flatten()\n",
        "          rmse = np.sqrt(mean_squared_error(iris.data[:, 2], y_pred))\n",
        "          rmses[num_epochs].append(rmse)\n",
        "      avg_rmses = {num_epochs : np.mean(rmses[num_epochs]) for num_epochs in try_epochs}\n",
        "      epochs_of_min_avg_rmse = min(avg_rmses, key=avg_rmses.get)\n",
        "      best_avg_rmse_candidate =  avg_rmses[epochs_of_min_avg_rmse]\n",
        "      if best_rmse[var] > best_avg_rmse_candidate:\n",
        "        best_rmse[var] = best_avg_rmse_candidate\n",
        "        best_learning_rates[var] = learning_rate\n",
        "        best_batch_sizes[var] = batch_size\n",
        "        best_epochs[var] = epochs_of_min_avg_rmse\n",
        "\n",
        "  print(f'{iris.feature_names[var]} gives us of an rmse of {best_rmse[var]}')\n",
        "\n",
        "t2 = time.perf_counter()\n",
        "print('Time taken to run:',t2-t1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Print the best settings found with this faster way\n",
        "print(f'{best_rmse=}')\n",
        "print(f'{best_epochs=}')\n",
        "print(f'{best_learning_rates=}')\n",
        "print(f'{best_batch_sizes=}')"
      ],
      "metadata": {
        "id": "-1w7AQMLvjh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce15e24-f6d2-4cce-c40c-47904b65f882"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best_rmse=array([0.94789953, 1.62971739, 0.00353695, 0.48129493])\n",
            "best_epochs=array([40., 40., 80., 80.])\n",
            "best_learning_rates=array([0.1 , 0.1 , 0.01, 0.01])\n",
            "best_batch_sizes=array([1., 1., 1., 2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Speed-up: Ratio of the runtimes\n",
        "5322 / 2801"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oemdvxMox5Qz",
        "outputId": "64b6a551-ee62-4da3-c162-4bc52554815b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.900035701535166"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ratio of the number of epochs performed: (10+20+40+80) vs (10+10more+20more+40more) either way we go up to 80 epochs\n",
        "150/80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ7qaTkNx751",
        "outputId": "4856b0b3-e33b-4818-9abd-7aecd71a5cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.875"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xaE79GpZx9bd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}